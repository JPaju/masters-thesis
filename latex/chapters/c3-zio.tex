\chapter{ZIO} \label{zio}
ZIO is a open-source Scala library/framework for managing effects and building concurrent applications. It is based on monadic effects but also takes influence from algebraic effects and handlers. ZIO aims to provide a pragmatic, purely functional, type safe, easily testable and declarative API for asynchronous and concurrent effectful programming. The ZIO ecosystem~\cite{zio} consists of tens of official and several third-party libraries that include among other things, testing, streaming, logging, caching, JSON-parsing, database and other infrastructure interaction, as well as HTTP servers and clients. Today, ZIO is one of the fastest growing and most used ecosystems in Scala.

The development of ZIO started in 2017 by John De Goes. The first stable version was released in August 2020. At the time of writing this, the most recent version is 2.0.6, released in January 2023. De Goes and Adam Fraser, a core contributor to the project, co-authored a book about ZIO called Zionomicon~\cite{zionomicon}, which is extensively used as a reference in this chapter.

The idea of ZIO is to combine multiple effects into a single monad and thus avoiding the need for monad transformers. The library is built around \inlinescala{ZIO[-R, +E, +A]} monad with three type parameters. \inlinecode{E} and \inlinecode{A} parameters represent the error and success channels, much like in Either monad, although ZIO is capable of describing asynchronous and side-effecting computations unlike Either. The \inlinecode{R} parameter describes the requirements, environment, or context, needed to perform the computation. It is similar to the reader monad, but has some extra capabilities that are introduced later in this chapter. Drastically simplifying, a ZIO computation can be seen as function from environment to either an error or a success value: \inlinescala{R => Either[E, A]}. The idea of ZIO's three type parameters is that it should be possible to encode most, if not all, of the effects in a single monad. 

ZIO focuses heavily on statically verifying the correctness of programs. With regards to error handling, environmental requirements, and dependency injection. The three type parameters of ZIO make it possible to statically check that expected errors are handled and the required environment is provided before the program can be executed. Error handling and the environment parameter are discussed in more detail in upcoming sections.

ZIO provides type aliases for common variants, among others:
\begin{itemize}
    \item \inlinescala{type UIO[A] = ZIO[Any, Nothing, A]} has no requirements and cannot fail
    \item \inlinescala{type IO[E, A] = ZIO[Any, E, A]} has no requirements and can fail with \inlinecode{E}
    \item \inlinescala{type URIO[R, A] = ZIO[R, Nothing, A]} has requirement \inlinescala{R} and cannot fail
\end{itemize}

Since ZIO is a monadic effect system, all computations are values that can be transformed with functions. This makes it easy to implement combinators for modifying ZIO-values, thus changing the behavior of the described computation. ZIO provides numerous built-in combinators for error handling, context management, dependency injection, concurrency, retrying and repeating, scheduling, memoizing, resource management, and more. It is also easy to implement complex custom combinators in terms of existing ones.

ZIO's approach to functional programming is pragmatic, aiming for an easy to learn, even for programmers without prior theoretical knowledge about functional programming concepts. Even though the library has strong theoretical foundations in functional programming, the aim is to not have them surface them in the public API more than required. ZIO constructors use lazy, by-name parameters to delay executing unintentional side effects until the ZIO effect is executed. Using ZIO does not require knowledge of concepts like type classes or monad transformers, even though the former is utilized heavily internally.

Function naming mostly avoids terms originating from category theory, symbolic operators, and naming conventions from Haskell. For example, functions corresponding to Haskell's \inlinecode{sequence}, \inlinecode{traverse}, and \inlinecode{bracket}, are named \inlinecode{collectAll}, \inlinecode{foreach}, and \inlinecode{acquireReleaseWith} in ZIO to make them easier to understand. A naming convention originating from Haskell where effectful combinators, such as \inlinecode{foldM}, \inlinecode{ifM}, and \inlinecode{replicateM}, are suffixed with \inlinecode{M}. The meaning of \inlinecode{M} might not be obvious to newcomers and ZIO aims to make it clearer by naming these combinators as \inlinecode{foldZIO}, \inlinecode{ifZIO}, and \inlinecode{replicateZIO}.
Haskell's convention to suffix the names of combinators that discard their result with \_, e.g. \inlinecode{sequence_} or \inlinecode{traverse_}, is not followed: ZIO names are are named \inlinecode{collecAllDiscard} and \inlinecode{foreachDiscard}.

ZIO also takes advantage of multiple advanced features of Scala to make the API more convinient to use. The implicit system is used to provide context information for tracing, derive type class instances and prove type relationships. Dependent types are used, for example, to destructure nested tuples when zipping together multiple ZIO values. There are several combinators that only make sense with specific success or error types. These operators utilize implicit evidence provided by the Scala compiler to make sure they are used appropriately. An example of such cases are error handling operators that are only applicable with effects that can actually fail. Metaprogramming is utilized for example in dependency injection where the the dependency graph is resolved and constructed at compile time, failing compilation if any of the required dependencies is not provided.

Monadic programming in Scala has traditionally suffered from the lack of type inference due to subtyping, forcing the programmer to explicitly write type annotations.
Prior to ZIO, many functional programming libraries in Scala implemented their monads with invariant type variables, because of the issues related to subtyping and type inference mentioned in section \ref{background:monad:monad-transformers} about monad transformers. Since ZIO does not use monad transformers, it does not suffer from limitations associated with them. ZIO embraces the subtyping and variance of Scala by declaring the error and success types covariant, and the environment type as contravariant. This makes type inference a lot more effective and in practice, explicit type definitions are rarely required when combining ZIO effects with different type parameters.



\section{Basic operators}
One of the most used operators are constructors that create ZIO values. Like every monad, ZIO also has a lifting function \inlinecode{ZIO.succeed}. In addition to lifting pure values, it also enables the lifting of non-fallible side effects to ZIO. For lifting side effects that might throw exceptions, \inlinecode{ZIO.attempt} is used. To create failed ZIO effects functions \inlinecode{ZIO.fail} or \inlinecode{ZIO.die} are commonly used. Error handling is discussed in more detail in Section \ref{zio:error-handling}. Constructors for data types from Scala standard library like \inlinecode{Option} and \inlinecode{Either} exist as well. Usage of the most common ZIO constructors is demonstrated in \refsource{zio:constructors}.

\input{sources/zio/constructors}

Starting from the more simpler operators, are the ones including a single ZIO value. Operator for applying a pure transformation to value inside ZIO is implemented by the \inlinecode{map} function. Operator to discard the value of the ZIO and map it to constant value is function called \inlinecode{as}. Common debugging operator for peeking the value inside ZIO without changing the value is called \inlinecode{tap}. ZIO also has specific \inlinecode{debug} operator that will print the value inside ZIO with the provided prefix. Mentioned operators are demonstrated in \refsource{zio:transform}.

\input{sources/zio/transform}

Other common category of operators are the ones combining two ZIO values together. The \inlinecode{flatMap} function present in all monads naturally exists in ZIO as well.
For combining two independent ZIO workflows together, there is a whole family of \textit{zipping} operators. Unlike monadic composition via \inlinecode{flatMap}, when zipping values together the second value cannot use the value produced by the first one. The most simple zipping operator, \inlinecode{zip}, simply runs both ZIOs from left to right and combines their result in a tuple. The \inlinecode{zipWith} allows to supply a function to combine the left and right value into the resulting ZIO. Sometimes a ZIO is only evaluated because of the effect it produces, and its return value is not needed. For these puproses \inlinecode{zipRight} and \inlinecode{zipLeft} operators are useful. These combinators evaluate both ZIOs from left to right, but retain only the return value of the side indicated by the operator name. Right and left zipping combinators also have symbolic aliases, generally quite rare in ZIO, \inlinecode{*>} and \inlinecode{<*}, where the arrow points to the side whose value is returned. The combinators for two ZIOs are demonstrated in \refsource{zio:binary-combinators}.

\input{sources/zio/binary-combinators}

When required to combine more than two ZIOs togheter, for example in a loop-like situation, there are operators for that as well. Effectful for loop is provided by the \inlinecode{ZIO.foreach} function, which takes a collection of values, and a function that performs some effectful computation for each value. The operator performs all computations and returns a collection of results. Similar operator is \inlinecode{collectAll}, which receives a collection of ZIO computations, and returns a collection containing the results of the computations. Both operators are demonstrated in \refsource{zio:multi-combinators}. In order to effectfully fold over a collection of values, ZIO provides, among others, \inlinecode{mergeAll}, \inlinecode{reduceAll}, \inlinecode{foldLeft}, and  \inlinecode{foldRight} functions to compute a single summary value from a collection.

\input{sources/zio/multi-combinators}



\section{Error handling} \label{zio:error-handling}
Proper error handling is essential in any non-trivial application, like mentioned in section \ref{effects:exceptions}. Failures in ZIO are described in a referentially transparent way by returning values that represent the error, instead of throwing exceptions. Like other monads capable of encoding exceptions, ZIO is stops execution of the success channel on first encountered error, until the error is handled with one of the error handling combinators. Much of the errors are tracked in types, making it possible to have static proof that all declared errors are handled. ZIO advocates its error model, which is promised not to lose any errors, even asynchronous, parallel, caused by interruptions, or exceptions thrown by finalizers.

ZIO divides failures into three categories: errors, defects and fatal errors. Fatal errors are thrown by the runtime platform (usually JVM), such as \inlinecode{OutOfMemoryError}, which results in immediate termination of the application, and thus are not very interesting in this context. The two remaining error types describe failures that are possible for the programmer to interact with. Errors are represented as the \inlinecode{E} parameter in ZIO, and are tracked in the types. \inlinecode{Nothing} has a cardinality of zero, which proves that ZIO with \inlinecode{Nothing} in the error channel cannot produce a failing ZIO, thus is infallible. Defects are not reflected in the types, and practically any ZIO can produce a defect when executed. The type of defect is always Java's \inlinecode{Throwable}.

The error channel should be used for business errors that are expected to happen and there is a meaningful way to handle and recover from. On the other hand, defects are failures that are unexpected, or there is no meaningful way to handle or recover from. Because Scala programs are mostly run on the JVM, where exceptions could be thrown anywhere, ZIO runtime catches all thrown exceptions and reports them as defects. This makes it easier to integrate with code not written with ZIO, such as Java-libraries where throwing exceptions is the de-facto error reporting and handling strategy. Roughly speaking, logical exceptions (discussed in section \ref{effects:exceptions}) are usually errors, while technical exceptions are usually defects.

Errors in ZIO are internally represented with a data type \inlinecode{Cause}, which is an algebraic structure called \textit{semiring}, that is capable of capturing the full chain of possible failures, including errors, defects, and interruptions, sequential or parallel. The data type also keeps track of a trace that lead to the failure described by a specific \inlinecode{Cause}. Trace is similar to ordinary stack trace but it is able to describe operations across asynchronous  boundaries and has an option not to expose unnecessary details of the underlying runtime implementation in the trace. ZIO provides operators to interact with the \inlinecode{Cause} data type directly, but usually higher level operators that work with error or defect types are preferred. Definition of simplified \inlinecode{Cause} data type and example of its usage is provided in \refsource{zio:cause}.

\input{sources/zio/cause}

When two ZIOs are composed together, the composed ZIO could fail either with the error from the first, or the error from the second one. The order in which the error types appear, should not matter and all permutations consisting of same types should be equal, i.e. the composition is commutative. If the two ZIOs share the same error type, the resulting ZIO has equal error type with the original ZIOs, i.e. the composition is idempotent. If either of the two ZIOs cannot fail (the error type is \inlinecode{Nothing}), its error type does not contribute to the resulting error type, i.e. the composition has \inlinecode{Nothing} as the identity element. Union types in Scala 3 naturally have all these properties and precisely expresses the composition of error types. Another way of thinking is to consider the error type as a set of possible error types, composition is set union of their errors and \inlinecode{Nothing} represents empty set. If the execution of the ZIO fails, the error is \textbf{one of} the errors in the set of possible errors. \refsource{zio:error-accumulation} demonstrates the accumulation of errors in types.

\input{sources/zio/error-accumulation}

Ideally there would be no need to explicitly add the type annotation about the error type when composing ZIOs toghether, and simply rely on type inference. Scala compiler tries automatically to \textit{unify} the types, i.e. find the closest common supertype between the composed ZIO values. The \inlinecode{E} parameter in ZIO is covariant, which is essential for type inference when combining multiple ZIOs together. Because \inlinecode{Nothing} is subtype of every type, ZIO that has \inlinecode{Nothing} in the \inlinecode{E} channel is automatically considered to be a subtype of ZIO that has same \inlinecode{R} and  \inlinecode{A} type parameters.

There are many similar operators for working with the values in the error channel as in the success channel. For example \inlinecode{mapError}, \inlinecode{flatMapError} and \inlinecode{tapError} all work similarly to their success channel counterparts. Some of the most common error handling operators include catching some or all errors, providing a fallback computation, or folding over error and success values. Operators \inlinecode{catchAll} and \inlinecode{catchSome} behave like catch blocks in a try-catch clause, and like the names suggest, it's possible to handle either a subset or all errors. The \inlinecode{orElse} operator makes it possible to define a fallback computation whose success and error is used in the case when the original ZIO fails. ZIO has many variations of \inlinecode{fold} for pure and effectful folding which are semantically similar to folding an \inlinecode{Either}, discussed more in section \ref{background:monads:either}). These basic error handling operators are demonstrated \refsource{zio:error-handling-operators}.

\input{sources/zio/error-handling}

In addition to \inlinecode{try-catch} like semantics described above, \inlinecode{try-finally} is a common pattern in imperative programming. Regardless whether the code in the \inlinecode{try} throw exceptions or not, the code in \inlinecode{finally} block guaranteed to be executed. The underlying idea is that there is finalizer(s) that need to be run after a certain block of code is executed. ZIO also supports this pattern with several operators that are guaranteed to execute the finalizers even in the presence of parallelism, asynchrony, concurrency, interruption, errors, and defects. \refsource{zio:finalizers} demonstrates the basic finalizing operator \inlinecode{ensuring} that executes the specified finalizer regardless of any kind of failure or interruption. Other, higher level, operators for \inlinecode{try-finally} like semantics are discussed more thoroughly in section \ref{zio:resource-management} about resource management.

\input{sources/zio/finalizers}

The fact that ZIO has two typed channels of output values (error and success), makes it possible to create interesting combinators that switch values between the two channels. Operator that simply swaps the channels with each other is \inlinecode{flip}. Another way to expose errors in the success channel is the \inlinecode{either} operator that converts fallible a ZIO to \inlinescala{ZIO[R, Nothing, Either[E, A]]}, resulting in an effect that cannot fail, but instead surfaces errors with \inlinecode{Either} in the success channel. The dual of \inlinecode{either} is the operator \inlinecode{absolve} that separates \inlinecode{Either} cases from the success channel to error and success channels of ZIO. The \inlinecode{Cause} data type could also be exposed in the success channel with the \inlinecode{cause} operator, making it possible to operate errors, defects and interruptions at the same time. The reverse operator is \inlinecode{uncause}, that hides the \inlinecode{Cause} data type from the type signature. Type signatures of mentioned operators can be seen in \refsource{zio:error-tricks}.

\input{sources/zio/error-tricks}

Same exceptions might be considered errors at some abstraction level, and defects at some other abstraction level. For example when implementing \acronym{DAO}{Data Access Object}, that is directly interacting with a relational database, it would be sensible to treat \inlinecode{SQLException} as error and expose it in the \inlinecode{E} parameter. On the other hand, higher level abstractions using the DAO, like repositories or services, usually should not to declare \inlinecode{SQLException} in their signature, and treat it as a defect.

ZIO contains operators for switching values from the error channel to defect channel and the other way round. Simple way to convert errors to defects is to consider all errors as defects, which could be achieved with the \inlinecode{orDie} operator that switches all errors from the error channel to defect channel. In order to have more control of what errors to retain, the \inlinecode{refineOrDie} operators are useful. They allow to pick desired errors by providing a type parameter or a partial function, and the operators converts all errors not matching the type parameter or partial function to defects. To go the other way round and switch values from the defect channel to error channel, \inlinecode{resurrect} operator moves all defects to errors and \inlinecode{unrefine} moves some defects to errors, like \inlinecode{refine} but the other way around. \refsource{zio:defect-handling} demonstrates the usage of these operators.

\input{sources/zio/defect-handling}

Sometimes when an error occurs, it can be resolved by retrying the operation that produced the error. Retries in ZIO only apply when the failure is in the error channel, and not in the defect channel. If one would like to retry even when defect happens, it must first be surfaced to the error channel. Probably the simplest retry operator is \inlinecode{eventually}, which will retry forever until the operation succeeds. Usually it makes sense to limit the number of retries, and \inlinecode{retryN} operator enables just that. For specifying a custom rules when to retry and when to give up, ZIO has \inlinecode{retryUntil} and \inlinecode{retryWhile} operators that take a predicate as a parameter and retry according to that predicate. Basic retry operators are demonstrated in \refsource{zio:retry}.

\input{sources/zio/retry}

Instead of immediately retrying, a common way is to schedule the retries with a delay in order to allow the error resolve. ZIO has specific data type for describing retry policies and other scheduling use cases called \inlinecode{Schedule}. It is a purely functional and composable data type capable of describing complicated schedules. In addition to retries, schedules are also applicable for describing the repetition and scheduling the execution of ZIO computations. \refsource{zio:schedule} introduces some basic \inlinecode{Schedule} constructors and combinators. When retrying ZIO with a delay, one might desire to limit the total time the computation can take, which is achieved with the \inlinecode{timeout} operator.

\input{sources/zio/schedule}



\section{Environment}
Arguably the most distinguishing feature about ZIO is its environment or \inlinecode{R} type. The possibility to express environmental/contextual requirements of a computation, plays a big part in the fact that ZIO can encode several effects in one monad, thus mostly eliminating the need for monad transformers. ZIO environment is similar to a reader monad, but has couple of key differences. Unlike reader monad whose only effect is to provide read-only access to some context, the ZIO environment is just a one of the effects that can be expressed with ZIO. Also the environment type composes naturally when combining multiple ZIO values. The environment type in ZIO can be changed from one type to another, similar to indexed reader monads~\cite{monad-factory}. Its also possible to locally both introduce environmental requirements and eliminate some or all environmental requirements.

Recall that a mental model of a \inlinecode{ZIO[R, E, A]} is function \inlinecode{R => Either[E, A]}.
Before a ZIO can be executed the required environment must be provided, just like function must be provided with the parameters before it can be evaluated. A ZIO workflow, that has no environmental requirements, has \inlinecode{Any} as its environment type. Function \inlinecode{f: Any => Either[E, A]} function accepts \textit{anything} as its argument and can be called, for example, by providing the unit value \inlinecode{f(())}, number \inlinecode{f(42)}, or string \inlinecode{f("foo")} as its argument. The analogy applies to ZIO, where \inlinecode{ZIO[Any, E, A]} is ready to be executed without providing any environment.

\input{sources/zio/environment-accumulation}

When combining ZIO values together, the resulting ZIO naturally has environmental requirements from \textbf{all} combined ZIOs. Similarly to error accumulation, the composition should be commutative and have \inlinecode{Any} as its identity element. Scala 3 intersection types have these properties and thus expresses the composition accurately. \refsource{zio:environment-accumulation} demonstrates the accumulation of environment types when composing ZIO values.

Basic operations for interacting with the environment are adding requirements to it and eliminating all or part of the requirements. It is also possible to translate one environmental requirement to another. A value from the environment can be accessed with \inlinecode{ZIO.service} function, which is really similar to the \inlinecode{ask} function in Reader monad with the exception that \inlinecode{ZIO.service} can return a part of the environment instead of the entire environment. \refsource{zio:environment-access} demonstrates different operators for accessing the environment, which add corresponding environmental requirements.

\input{sources/zio/environment-access}


\subsection{Zlayer}
Environmental requirements in ZIO are provided in the form of a purely functional data type called \inlinecode{ZLayer}. \inlinecode{ZLayer[RIn, E, ROut]} has same three type parameters as ZIO itself, and thus is capable of expressing effectful, asynchronous, and possibly failing construction of requirements. The \inlinecode{RIn} parameter in \inlinecode{ZLayer} represents dependencies that are required in order to construct value of type \inlinecode{ROut}. These dependencies between layers form a graph of dependencies, like demonstrated in \refsource{zio:zlayer-graph}.

\input{sources/zio/zlayer-graph}

Environment for a ZIO workflow is provided with operators such as \inlinecode{provide} (provide all requirements), \inlinecode{provideSome} (provide a part of requirements), and \inlinecode{provideLayer} (convert existing requirements into other requirements), that take \inlinecode{ZLayer}(s) as their argument. Also the \inlinecode{apply} method in \inlinecode{ZLayer} can be used to eliminate requirements from a ZIO workflow. ZIO can resolve the dependency graph with compiler macros, for example in \inlinecode{ZIO.provide} and \inlinecode{ZLayer.make} functions, and raise a compilation error if all required dependencies are not provided. Different ways of providing layers is demonstrated in \refsource{zio:zlayer-provide}.

\input{sources/zio/zlayer-provide}

\inlinecode{ZLayer}s along with ZIO environment are the basis of dependency injection in ZIO. Dependency injection in ZIO is resolved statically at compile time, so program with missing dependencies won't compile. Although there are several conventions and patterns related to dependency injection in ZIO programs, they are not discussed in more detail in this thesis.
\todo{Onko tarpeellinen/sopiva maininta?} 


\subsection{ZEnvironment}
Example in \refsource{zio:environment-accumulation} had ZIO value \inlinecode{composed} that has \inlinescala{String & Int} as the environment type. It is not possible for the type to exists at runtime, since there is no type that is both \inlinecode{String} and \inlinecode{Int}, so the type is only sensible at compile time. These kind of types that only exist at compile time are sometimes called \textit{phantom types}~\cite{fun-phantom-types}.

The \inlinecode{R} type parameter in ZIO is a phantom type, and therefore represents the required types only at compile time. However, every type present in the environment type intersection must have a corresponding value at runtime. This is achieved with a data type called \inlinecode{ZEnvironment[R]}, which is can be seen as a map associating every type in the environment type intersection to a value, as demonstrated in \refsource{zio:zenvironment}.

\input{sources/zio/zenvironment}

With this knowledge, the mental model of ZIO can be updated to be \inlinecode{ZEnvironment[R] => Either[E, A]}. Since \inlinecode{ZEnvironment} is a low-level data type used internally to represent the environmental requirements of ZIO, it's not advised to use it directly, but instead use higher-level operators and data types such as \inlinecode{ZLayer}.


\subsection{Use cases}
The ZIO environment can be used in many ways. In addition to providing read-only data to computations like reader monad, it can be utilized in other interesting ways as well. It can describe mutable state, safe resource management (discussed more in Section \ref{zio:resource-management}), or dependency-injection. One could also use environmental requirement as a marker that certain ZIO computation must be run in a specific context. Another common use-case is to define combinators that translate a certain environmental requirement into another.

Probably the most basic use-case is to provide some static data/context, which the computation can use as it wishes. Example of such data is configuration data in a web application, possibly containing a URL for performing http requests. This is demonstrated in \refsource{zio:environment-simple}.

\input{sources/zio/environment-simple}

Another use case is to encode mutable state in the environment, similar to monad transformer for \inlinecode{State} monad. This is achieved with data type describing mutable references evaluated in the ZIO monad, such as \inlinecode{Ref} or \inlinecode{ZState} which is purposefully built for this use case. State can be accessed with \inlinecode{ZIO.getState} function, which also adds a state requirement to the environment. State requirement can be eliminated using the \inlinescala{ZIO.stateful} operator by providing the initial state. \refsource{zio:state} demonstrates the usage of these operators in stateful computation. A nice byproduct of encoding state in the ZIO environment, is that the environment can carry several different states at the same time, as long as the states are of different types.

\input{sources/zio/state}

Environmental requirements can be converted from one type to another by eliminating one requirement and adding a new one. \refsource{zio:user-session} demonstrates one such situation. In that example \inlinecode{businessLogic} requires a \inlinecode{UserSession} from the environment. There is a \inlinecode{UserService} that can validate a token (\inlinecode{String} in this case) and succeed with \inlinecode{UserSession}, or fail validation with \inlinecode{TokenError}. For example, in the context of a web application, a token could be extracted from the http request. The helper function \inlinecode{UserService.withSessionFromToken} takes two parameters: a token and a ZIO computation that requires \inlinecode{UserSession} from the environment, and returns a ZIO computation that requires \inlinecode{UserService} from the environment, which will be used to validate the token. If the validation is successful a \inlinecode{UserSession} is provided to the computation. If validating the token fails, it fails the whole computation with \inlinecode{TokenError} and the computation received as a parameter will not be executed. The possibility that validating the token might fail can be observed from the fact that  \inlinecode{TokenError} is added to the error type of the returned ZIO computation.

\input{sources/zio/user-session}

The power of the environment type comes from the fact that it supports many different overlapping use cases. For example, configuration, state, and sessions can coexist in the environment without interfering with each other. The environment can be provided locally to a specific computation or globally to the entire program.


\subsection{Similarity to algebraic effects}
It may not be immediately obvious how ZIO is similar to algebraic effects and handlers.
However, if we consider that each type in the environment intersection represents a specific effect, adding or interacting with environmental requirements represents an effectful operation, and removing environmental requirement with \inlinecode{ZLayer} represents handling an effect, the similarity is imminent. 
\refsource{zio:zlayer-eff-handler} 

Like handlers in algebraic effects, \inlinecode{ZLayer}s can handle (or discharge) the effect by removing it altogether, or it can translate one effect into another. Similar to handlers in algebraic effects, \inlinecode{ZLayer}s commonly form a graph of dependencies between other \inlinecode{ZLayer}s. ZIO environment composes in similar way as effects in language that natively supports algebraic effects and handlers, such as Unison.

With \inlinecode{ZLayer}s it is possible to define polymorphic handler, which only handles a subset of all effects in a specific expression. In practice this means that a \inlinecode{ZLayer} eliminates only a part of the environment, while leaving the rest in place. \refsource{zio:zlayer-eff-handler} demonstrates the mentioned similarity and polymorphic handlers.

\input{sources/zio/zlayer-eff-handler}

Effect polymorphism (demonstrated in Listings \ref{scala:cc-eff-polymorphism}, \ref{alg-eff:polymorphism-unison}, and \ref{alg-eff:polymorphism-koka}) is limited since every ZIO computation is evaluated in monadic context, however. Also handlers in ZIO are not as expressive, since they do not receive a continuation to the rest of the program like algebraic effects handlers.


\section{Resource management} \label{zio:resource-management}
At a high level, resource management consists of three parts: acquiring resources, using resources and releasing resources after they are used and no longer needed. Countless things can be viewed as resources that need to be acquired and released: concurrency or database locks, allocated memory, open file handles or network sockets, connections from a connection pool, or spawned processes/threads. Even a database transaction is special kind of resource where releasing it either commits the transaction or rolls it back.

The important part is that once a resource is acquired, it must be released, even if using the resource raises an exception or fails in any other way. This behavior is can be described with contextual data type that is added to the environment when the resources are acquired, and stays in the environment as long as there are resources that need to be released. A consequence of this is that acquired resources are visible in the type signature, and the compiler is able to help in making sure that acquired resources are actually released.

Safe resource management in ZIO relies on information threaded through computations in the ZIO environment. In ZIO, the data type describing lifetime of resources is called \inlinecode{Scope}. In principle, a \inlinecode{Scope} is very simple and has only two operations: one to add a finalizer that is executed when the scope is closed, and one to actually close the scope. Computation that acquires a resource, requires that a \inlinecode{Scope} is in the environment. After the resource is acquired, a finalizer for releasing the resource is added to the scope. Before the ZIO is executed, the \inlinecode{Scope} must be provided. The provided \inlinecode{Scope} determines how long the resource is usable and when it is released. 

To create a resource, ZIO has \inlinecode{acquireRelease} constructor and several variants for it. Like the name suggests, these constructors take two ZIO computations as their parameter: one to acquire the resource and one to release it. They return a ZIO computation that succeeds with the resource, and have added \inlinecode{Scope} to the environment. In order to determine the extent of a \inlinecode{Scope} and remove it from the environment, ZIO provides a operator called \inlinecode{scoped}. It takes a ZIO computation with requirement to scope as a argument, provides the scope, runs the computation with the scope and finally closes the scope. Several resourceful ZIOs could be interpreted in a different ways depending how the \inlinecode{Scope} is provided, which changes the order of acquire and release, in other words the lifetime of the resource. \refsource{zio:scope} demonstrates usage of these operators, and how scoping affects the order of acquiring and releasing resources.

\input{sources/zio/scope}

If multiple resources are acquired, they are released in the reverse order. By default releasing resources happens sequentially, but \inlinecode{Scope} also enables to run finalizers in parallel if configured so. 
When using \inlinecode{Scope} with \inlinecode{ZIO.scoped}, finalizers are guaranteed to be executed even when error/defect is encountered, or when the workflow is interrupted.

Traditionally resource management is implemented with \inlinecode{try-finally} statement, where the resource is acquired, before using it in \inlinecode{try} block, and lastly releasing it in the \inlinecode{finally} block. This guarantees that the resource is released, even if error occures after acquiring the resource. Managing resources with \inlinecode{try-finally} lacks in expressivity, composability, and safety compared to higher-level declarative strategy like \inlinecode{Scope}. Firstly, the acquired resource is not visible in the type system, so it is possible to forget to release the resource. Composing acquisition and release of several resources with \inlinecode{try-finally} can be complicated, especially if the acquisition and release must be done in a certain order. When resource is acquired, the lifetime of the resource must be statically determined (by adding a \inlinecode{finally} statement).



\section{Concurrency}
\todo{Siirr√§ concurrency-osuus background-lukuun?}
Modern applications often use IO a lot, whether it be communicating over the network or interacting with the file system. It is characteristic of IO that a large proportion of time is spent waiting for a response, rather than calculating results utilizing local compute resources, mainly CPU. Today's hardware is capable of executing multiple processed in parallel. In order to increase the throughput and efficiency of an application, many workflows should be executed concurrently to maximize the utilization of the hardware.

Often concurrent workflows must interact with other workflows. A parent workflow might create multiple child workflows to execute some logic in parallel, and combine the results of all workflows, once they are finished. Sometimes a task ought to be split up between concurrent workflows in such way that no two workflows execute the same task. These results of the parallel execution must also be collected together once finished. In some situations, one might \textit{race} workflows i.e. run several workflows in parallel and choose the result that is computed the fastest, discarding all other results. Concurrent workflows sometimes must use a shared resource like mutable data structure, file, or connection to database. Sometimes parallel workflows do not interact with each other in any way, and the focus is to maximize the utilization of the hardware.


\subsubsection{Concurrency problems}
By default the execution order of parallel workflows is nondeterministic, because of how tasks are scheduled (usually) by the operating system to run on actual hardware. Concurrent workflows interacting with each other may be susceptible to race conditions, where the program might behave differently depending on the order of execution. In order to avoid race conditions, explicit countermeasures are required. Logic used to split work between workflows must guarantee that a single task is given only to a single workflow. The logic for collecting the results of parallel workflows must make sure that all results are combined correctly together. The access for a shared resource must be coordinated in a way where only a single or pre-determined number of workflow(s) has access to the resource at given point of time.

At first glance, the problems above may seem trivial, but concurrency really complicates the matter a lot. Very few statements in any programming language are executed with a single CPU instruction, but are usually a combination of several CPU instructions, executed sequentially at different clock cycles. A canonical example of this is the increment operator (\inlinecode{++} or \inlinecode{+=}) found in many languages consists of multiple instructions where the current value of the variable is first read and then set to updated value. If another parallel workflow is updating the same variable at the same time, it might see the value between the two instructions, even though that is rarely the desired behavior. Many bugs related to concurrency are significantly more complex than the mentioned bug.

There are several data structures, constructs, and even CPU instructions for enforcing constraints on concurrent interactions. Atomic compare-and-swap operations enable to observe and update some data, succeeding only if the data was not modified by another workflow in between. Queue is a data structure that could be used to distribute work between multiple workflows. Producers put tasks into the queue and it is guaranteed that each task is only delivered to single a worker. Access to shared resources or parts of the code could be constrained to single workflow at the time with a lock, or mutex, that both grants exclusive access to single workflow at a time. Semaphore is like mutex, but contains a predetermined number of permits instead of just one.

Compare-and-swap operation can fail if the value was updated by another workflow concurrently. In this case the update should be retried, until it succeeds. Usually the retry logic requires significantly more code than a simple variable assignment. When the program has multiple locks that must be held at the same time, the possibility of deadlocks arise. Deadlock is a situation where concurrent workflows are blocked by each other and neither can continue until the other release lock/mutex they are holding.


\subsubsection{Structured concurrency}
\todo{Mihin kohtaan structured concurrency sopii?}
When parent workflow spawns many child workflows to split a task between them, it is common that if one of the children encounter an error, the result cannot be computed at all and thus the results of other sibling workflows are not needed anymore. Similar situation happens when racing workflows, after the first workflow successfully computes a result, the results of other workflows are no longer needed. In both of the situations it would be ideal to cancel the workflows whose results are not needed to preserve compute resources and make sure that no concurrent workflows remain in execution. Traditional concurrency primitives, such as threads, do not offer this kind of control out of the box.

Solution to this is \textit{structured concurrency}, which makes it possible to define clear semantics on if and how a child workflow could outlive its parent. The basic idea of structured concurrency is that there is a way to govern how child workflows are handled when the parent workflow completes (by succeeding or failing), or when there is an error encountered in any of the sibling workflow. For example if a parent workflow that spawns a child workflows and the parent completes or is cancelled before the children are finished, one would like to define whether the children should be awaited, cancelled, or left orphaned.

Native support for structured concurrency in programming languages is still quite rare, but it has been added into programming languages at an accelerating pace. Kotlin added structured concurrency back in 2018~\cite{kotlin-sc}, Swift 5.5 in 2021~\cite{swift-sc} and Java 19 in 2022~\cite{java-sc}. The feature will probably find its way into more programming languages in the future.


\subsubsection{Physical and semantic blocking}
Some function calls might take a long or even indefinite time to complete. This is especially evident when concurrency is involved. There are three main reasons why a function might take a long time to complete; IO, long running CPU intensive computation, or waiting on another workflow to complete. When a function takes a long time to return to it's caller, its said to be \textit{blocking}. Blocking caused by CPU intensive computation is necessary, but blocking, IO bound computations are not utilizing the hardware in a useful way and should be avoided when possible. Blocking can be semantic or physical. Semantic blocking is defines how programs are structured around blocking constructs, and physical blocking determines how the OS and hardware-level resources executing the program are utilized.

Semantic blocking is mandatory since certain operations like, waiting response from a user or remote service can take indefinite time, and the result is required by further computations. Physical blocking in the other hand is not necessary and actually should be avoided, because it prevents the current thread from doing useful work and encourages to create more threads to compensate for the blocked threads (the bad consequences of which are explained below). The line between physical and semantic blocking is often blurry, which is quite understandable considering how they influence the implementation of each other.

There are different techniques for expressing and implementing semantic blocking depending on the programming paradigm, language, and library. A trivial approach is to semantically block on every function call, but often more control over what can be executed concurrently is desired. A common approach is to reverse the responsibility and provide a \textit{continuation} function, which represents the rest of the program, that will be invoked in the future when the result is available. This type of interface is called a callback-based API.

Many languages and libraries have a Future/Promise data type, that is a handle to ongoing computation that should complete in the future, and provides an API to define additional behavior such as timeout, error handling, and interact with the result when the computation completes. Examples of such data types are \inlinecode{Promise} in JavaScript, \inlinecode{Task} in C\# and \inlinecode{Future} in Java.

Another common approach are Monadic APIs, that mostly abstract over blocking behavior in a opaque way. Monadic and Future/Promise based APIs are often implemented in terms of callbacks.

Several programming languages, such as JavaScript, C\# and Kotlin, have specific keywords, usually \textit{async} and \textit{await}, that make it possible to define exactly where the semantic blocking should happen. Compilers and interpreters are able to make a transformation (usually to a state machine or continuation-passing style) from callback-based or Future/Promise API to a one that allows to expose async/await to the programmer.


\subsubsection{Concurrency primitives}
In practice concurrency can be implemented with many different constructs. The lowest-level construct commonly accessible to programming languages is a \textit{thread}. It is a \acronym{OS}{Operating System} level abstraction for concurrent execution. Each thread has its' own stack, instruction pointer and \acronym{CPU}{Central Processing Unit} register values. All threads created by a single process share the same memory space, i.e. are able to read and write shared to same memory blocks.

Threads are run on the actual hardware of the computer, enabling a modern multi-core CPU to execute several workflows in parallel. The OS \textit{schedules} different threads for execution, and after a thread has been executing for a scheduled amount of time, the operating system interrupts the execution and switches the execution to a different thread. The operation where a CPU core switches the execution from one thread to another is called \textit{context switch}. Context switch requires that CPU registers and stack of the previous thread are saved, and respectively registers and stack of the new thread is loaded to the CPU.

% Threads
Traditionally a thread has been the concurrency primitive to turn to when some form of parallelism is required. Threads, however, are not a lightweight construct and they can exist in limited numbers, usually in the thousands. Context switch between threads involves significant amount of work, and thus causes performance overhead. Often context switch defeats many optimizations in contemporary CPUs like caching, pipelining and speculative execution, which in turn amplifies the performance overhead. The situation gets worse when the number of threads increases because the operating system tries to allocate execution time to each thread in a fair way, and the number of context switches increases since each thread has shorter time slot to execute. The issue manifests itself particularly when in highly concurrent scenarios where the computations are IO bound, which is usually the case in web and enterprise applications.

% Thread pools
A common way to constrain the total number of threads and increase their reuse, is to collect multiple threads into a \textit{pool} of threads, where tasks could be submitted for execution instead of operating with individual threads. Once task is submitted to a thread pool, its queued and run once there are available threads. This way many concurrent workflows could be \textit{multiplexed} into smaller number of physical threads. When fewer threads are created and reused by multiple concurrent workflows, the intent is to decrease the number of context switches in the hope of performance gains. There are different types of thread pools depending on how threads in the pool are created. Some thread pools have fixed number of threads, while others grow and shrink dynamically.

% Cooperative scheduling
Thread pools do not solve the problem that when a thread is waiting an IO operation or another thread to complete, the waiting thread is blocked. When a thread blocks, the OS puts it in a waiting state, meaning that it's execution is not continued until the event it is waiting on is triggered. The ideal solution would be that no physical threads are blocked, and blocking is only semantic. This is not possible when the threads are preemptively scheduled by the OS. A solution is to change the scheduling model from preemptive to \textit{cooperative}. Cooperative scheduling means that when a workflow is about to be blocked, it will register itself to be scheduled once all of its dependencies are met, and yield the control to another workflows. In this model no physical threads need to be blocked.

% Event loops
Cooperative scheduling is usually implemented by a runtime environment, programming language, or library, that runs on top of preemptively scheduled OS threads. Event loop is a common pattern to implement cooperative scheduling, and it is used extensively in asynchronous IO or single-threaded environments like JavaScript. The idea is to have a queue that contains computations waiting to get executed, and the event loop picks up and executes tasks from the queue one at a time. Once a task is about the do a blocking operation, it registers a callback. The callback is invoked when the blocking operation completes, and it will add another task to the queue that represents the remaining of the workflow.

% Fibers
Another way to implement cooperative scheduling is \textit{fibers}. They are lightweight threads that are managed and scheduled in the application instead of OS. Each fiber contains a stack and possibly error handlers or thread-local variables, similar to a thread. Fibers require a runtime that schedules fibers to run on actual OS threads. The runtime can multiplex many fibers to run on smaller number of physical threads. Fibers could exist in the hundreds of thousands or millions, and switching execution from one fiber to another is very cheap in comparison to context switch between threads. The fiber runtime can assign a fiber to run on specific CPU core, that will make it easier to reap benefits from CPU optimizations like caches.


\section{ZIO concurrency}
ZIO values are descriptions of a workflow that can be executed in different ways. They can be executed sequentially or concurrently, and the decision can be made after a ZIO workflow is defined. This makes ZIO, or any other IO monad, ideal for high level combinators that allow the programmer to precisely define the concurrency semantics of a computation.

The concurrency model in ZIO is based on fibers. Every operation that waits another ZIO/fiber to complete is semantically blocking and not blocking actual threads. If interacting with code doing blocking IO, ZIO has a separate thread pool dedicated for blocking operations. Extending ZIO's declarative nature is structured concurrency by default and related operators, that enable one to express error handling properties and interruption. Additionally ZIO offers many concurrency primitives such as queues, atomic references and semaphores, as well as software transactional memory, which are not discussed in more depth in this thesis.

Every ZIO workflow is executed by a fiber that is in turn executed by the ZIO runtime that assigns and schedules fibers to be run on actual threads. In ZIO, fiber is a datatype that is a handle to ongoing computation. ZIO program is started on a fiber created by the runtime called \textit{main fiber}. Additional fibers could be created with the \inlinecode{fork} operator on a ZIO workflow. The \inlinecode{fork} operator starts executing the forked fiber concurrently in the background and returns immediately to the original fiber. Other common operations with fibers are to check whether it's finished (\inlinecode{poll}), wait for the result (\inlinecode{join} and \inlinecode{await}), or to interrupt its execution (\inlinecode{interrupt}). Most operations on fibers are effects, and thus return their result inside a ZIO. \refsource{zio:forking} demonstrates forking and joining a fiber.

\input{sources/zio/forking}

Structured concurrency in ZIO is implemented with a fiber \textit{supervision} model. Every forked fiber in ZIO has a scope that determines the maximum lifetime of a fiber. When a scope is closed, all fibers belonging to that scope that have not finished executing are interrupted. The scope is determined at the time of forking, depending on which operator the forking is done with. It is also possible to change the scoping of a fiber after it is forked, but it is somewhat rare. \refsource{zio:fork-operators} introduces different forking operators and their type signatures.

\input{sources/zio/fork-operators}

The default is to scope child fibers to their parent, which is achieved with \inlinecode{fork} operator. In order for a fiber to outlive its parent, a different operator is required. If a fiber should live forever, independently from its parent, \inlinecode{forkDaemon} operator attaches fiber to \textit{global scope} that is closed only when the whole application exits. For finer-grained control over the scope of fiber, its lifetime could be tied to ZIO \inlinecode{Scope}, with \inlinecode{forkScoped} operator, which is scoped to surrounding \inlinecode{Scope} in the ZIO environment, or \inlinecode{forkIn} operator, which takes a \inlinecode{Scope} as an argument. \refsource{zio:fiber-scopes} demonstrates forking fibers in different scopes and their interruption properties.

\input{sources/zio/fiber-scopes}

The fibers of an application can be thought of as a tree where the main fiber is the root node, new child nodes are created by a \inlinecode{fork} operation, and each parent fiber is the root node of its subtree, from which all child fibers branch. When fiber terminates, either by succeeding, failing, or by interruption, all of its descendant fibers are recursively interrupted. After the child fibers have been interruped current fiber's finalizers are executed. Call to interrupt a fiber blocks until the fiber has interrupted all of its children, and all finalizers have finished executing. If a fiber has a large number of descendants with long-running or many finalizers, the interruption could take a significant amount of time. Sometimes it is desired to perform the interruption in the background by a daemon fiber and return immediately to the fiber that initiated the interrupt. This can be achieved by interrupting the fiber with \inlinecode{interruptFork} method or by using \inlinecode{disconnect} combinator on ZIO workflow to make the interruption happen in the background.

Sometimes a fiber is doing critical work, such as disposing acquired resources, that cannot be interrupted without leaving the program in an inconsistent state. These parts of the program should therefore be executed without interruptions. ZIO guarantees that if a fiber, that is executing a section marked as uninterruptible, is interrupted by another fiber, the uninterruptible section is executed to completion despite the interruption. A ZIO workflow can be marked as uninterruptible with \inlinecode{uninterruptible} and \inlinecode{uninterruptibleMask} operators. The former marks whole ZIO workflow as uninterruptible, while the latter gives more control over what parts inside a uninterruptible section are interruptible.

Fibers along with other concurrency primitives are basic building blocks in creating concurrency operators in ZIO. Countless concurrent and parallel combinators can be implemented with forking, joining and interrupting fibers in various ways. Combinators implemented with fibers automatically inherit structured concurrency properties like supervision, scoping and interruption. \refsource{zio:fiber-zippar} demonstrates how \inlinecode{zipPar} concurrency operator can be implemented by using fibers.

\input{sources/zio/fiber-zippar}

Fibers are a low-level construct and programming directly with them is error-prone because of possible race conditions. ZIO has numerous built-in high-level concurrency operators (a few of which are presented below) that should be used when possible instead of using fibers. Operators that combine multiple ZIOs in parallel are usually suffixed with \inlinecode{Par} to indicate that the execution happens in parallel. For majority of the operators that combines several independent ZIOs, there is a parallel counterpart that executes in parallel. Listings \ref{zio:binary-combinators} and \ref{zio:multi-combinators} demonstrated ZIO combinators that combine several ZIOs sequentially, whose parallel counterparts include \inlinecode{zipPar}, \inlinecode{foreachPar}, and \inlinecode{collectAllPar}, to name a few. Some operators only make sense to be defined as parallel, such as \inlinecode{race} and its variants, that execute multiple ZIOs and picks the one that succeeds first.

Many combinator operators (like \inlinecode{foreach}, \inlinecode{collectAll}, and every \inlinecode{zip} variant) need the result of each combined ZIO in order to compute a result, and as a result if even one of the ZIOs to be composed fail, the result cannot be computed. In sequential composition this is simple because if a ZIO fails, the execution of subsequent ZIOs won't be started. When composing ZIOs in parallel, this gets a little more complicated. All composed ZIOs start executing in parallel and if any of them fails, the results of others are not needed anymore and they are interrupted. In some situations this interrupting behavior is not desired, and can be avoided by converting ZIOs to infallible, with operators described in Section \ref{zio:error-handling}, before the parallel composition. \refsource{zio:parallel-combinators} demonstrates \inlinecode{zipPar} operator and interruption associated with it.

\input{sources/zio/parallel-combinators}

By default parallel combinators in ZIO have unbounded parallelism, meaning that all composed ZIOs are executed at the same time. Often one would want to limit the amount of parallelism especially with operators, like \inlinecode{foreachPar} or \inlinecode{collectAllPar}, whose parallelism is defined by the size of a collection received as an argument. ZIO has two basic operators for controlling the amount parallelism: \inlinecode{withParallelism} that limits concurrency to a number received as argument, and \inlinecode{withParallelismUnbounded} that removes any limitations to parallelism. These operators only apply to single ZIO workflow, meaning that parallelism is limited only in a specific ZIO. Composing ZIOs with varying parallelism limits preserves the parallelism of each individual ZIO workflow. \refsource{zio:limit-parallelism} demonstrates the usage of operators controlling the amount of parallelism.

\input{sources/zio/limit-parallelism}


\todo{Kokoa yhteen huomioita ZIO:sta ?}
% Expressivity
% Composability
% Type safety
% Comprehensibility
% Interoperability with existing libraries (even Java)
% Although quite new, few years of production experience from large companies
